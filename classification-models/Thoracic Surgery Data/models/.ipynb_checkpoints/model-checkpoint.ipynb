{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on Thoracic Surgery Dataset\n",
    "### 1.Importing Thoracic Surgery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DGN  PRE4  PRE5     PRE6  PRE7  PRE8  PRE9 PRE10 PRE11    PRE14  \\\n",
      "0    b'DGN2'  2.88  2.16  b'PRZ1'  b'F'  b'F'  b'F'  b'T'  b'T'  b'OC14'   \n",
      "1    b'DGN3'  3.40  1.88  b'PRZ0'  b'F'  b'F'  b'F'  b'F'  b'F'  b'OC12'   \n",
      "2    b'DGN3'  2.76  2.08  b'PRZ1'  b'F'  b'F'  b'F'  b'T'  b'F'  b'OC11'   \n",
      "3    b'DGN3'  3.68  3.04  b'PRZ0'  b'F'  b'F'  b'F'  b'F'  b'F'  b'OC11'   \n",
      "4    b'DGN3'  2.44  0.96  b'PRZ2'  b'F'  b'T'  b'F'  b'T'  b'T'  b'OC11'   \n",
      "..       ...   ...   ...      ...   ...   ...   ...   ...   ...      ...   \n",
      "465  b'DGN2'  3.88  2.12  b'PRZ1'  b'F'  b'F'  b'F'  b'T'  b'F'  b'OC13'   \n",
      "466  b'DGN3'  3.76  3.12  b'PRZ0'  b'F'  b'F'  b'F'  b'F'  b'F'  b'OC11'   \n",
      "467  b'DGN3'  3.04  2.08  b'PRZ1'  b'F'  b'F'  b'F'  b'T'  b'F'  b'OC13'   \n",
      "468  b'DGN3'  1.96  1.68  b'PRZ1'  b'F'  b'F'  b'F'  b'T'  b'T'  b'OC12'   \n",
      "469  b'DGN3'  4.72  3.56  b'PRZ0'  b'F'  b'F'  b'F'  b'F'  b'F'  b'OC12'   \n",
      "\n",
      "    PRE17 PRE19 PRE25 PRE30 PRE32   AGE Risk1Yr  \n",
      "0    b'F'  b'F'  b'F'  b'T'  b'F'  60.0    b'F'  \n",
      "1    b'F'  b'F'  b'F'  b'T'  b'F'  51.0    b'F'  \n",
      "2    b'F'  b'F'  b'F'  b'T'  b'F'  59.0    b'F'  \n",
      "3    b'F'  b'F'  b'F'  b'F'  b'F'  54.0    b'F'  \n",
      "4    b'F'  b'F'  b'F'  b'T'  b'F'  73.0    b'T'  \n",
      "..    ...   ...   ...   ...   ...   ...     ...  \n",
      "465  b'F'  b'F'  b'F'  b'T'  b'F'  63.0    b'F'  \n",
      "466  b'F'  b'F'  b'F'  b'T'  b'F'  61.0    b'F'  \n",
      "467  b'F'  b'F'  b'F'  b'F'  b'F'  52.0    b'F'  \n",
      "468  b'F'  b'F'  b'F'  b'T'  b'F'  79.0    b'F'  \n",
      "469  b'F'  b'F'  b'F'  b'T'  b'F'  51.0    b'F'  \n",
      "\n",
      "[470 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy.io import arff\n",
    "\n",
    "#Importing Thoracic Surgery Dataset\n",
    "dataset = arff.loadarff('C:/Users/Manan/Desktop/Fall 2019/Machine Learning COMP6321/Project/Machine-Learning-Project/classification-models/Thoracic Surgery Data/data/ThoraricSurgery.arff')\n",
    "data = pd.DataFrame(dataset[0])\n",
    "print(data)\n",
    "#X = DGN2,2.88,2.16,PRZ1,F,F,F,T,T,OC14,F,F,F,T,F,60\n",
    "datatype = np.array(['D','C','C','D','D','D','D','D','D','D','D','D','D','D','D','C'])\n",
    "X = data.iloc[:, :16].values\n",
    "Y = data.iloc[:, 16].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the discrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the discrete data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "for i in range(0,16):\n",
    "    if datatype[i]=='D':\n",
    "        X[:,i]  = labelencoder.fit_transform(X[:,i])\n",
    "\n",
    "Y = labelencoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitting encoded dataset into Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbours classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier Accuracy :83.68794326241135%\n"
     ]
    }
   ],
   "source": [
    "#Using KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('KNeighborsClassifier Accuracy :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernal SVM Accuracy :84.39716312056737%\n",
      "RBF Kernal SVM Accuracy :84.39716312056737%\n"
     ]
    }
   ],
   "source": [
    "#Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('Linear Kernal SVM Accuracy :'+str(accuracy*100)+\"%\")\n",
    "\n",
    "#Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('RBF Kernal SVM Accuracy :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Accuracy :70.2127659574468%\n"
     ]
    }
   ],
   "source": [
    "#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('DecisionTreeClassifier Accuracy :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomTreeClassifier Accuracy :83.68794326241135%\n"
     ]
    }
   ],
   "source": [
    "#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('RandomTreeClassifier Accuracy :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :84.39716312056737%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Using Logistic Regression Algorithm to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('Logistic Regression :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "print('GaussianNB Accuracy :'+str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
