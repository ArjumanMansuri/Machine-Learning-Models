{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Importing Bike Sharing Dataset\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"?\"]\n",
    "dataset = pd.read_csv('hour.csv', na_values = missing_values)\n",
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Contains Missing values                 False\n",
      "-> Total Number of Missing values:         0\n",
      "-> Number of Missing values by column\n",
      "instant       0\n",
      "dteday        0\n",
      "season        0\n",
      "yr            0\n",
      "mnth          0\n",
      "hr            0\n",
      "holiday       0\n",
      "weekday       0\n",
      "workingday    0\n",
      "weathersit    0\n",
      "temp          0\n",
      "atemp         0\n",
      "hum           0\n",
      "windspeed     0\n",
      "casual        0\n",
      "registered    0\n",
      "cnt           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has null values\n",
    "result = dataset.isna()\n",
    "print(\"-> Contains Missing values                 \",end='')\n",
    "print(result.values.any())\n",
    "print(\"-> Total Number of Missing values:         \",end='')\n",
    "print(result.sum().sum())\n",
    "print(\"-> Number of Missing values by column\")\n",
    "print(result.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      "instant       17379 non-null int64\n",
      "dteday        17379 non-null object\n",
      "season        17379 non-null int64\n",
      "yr            17379 non-null int64\n",
      "mnth          17379 non-null int64\n",
      "hr            17379 non-null int64\n",
      "holiday       17379 non-null int64\n",
      "weekday       17379 non-null int64\n",
      "workingday    17379 non-null int64\n",
      "weathersit    17379 non-null int64\n",
      "temp          17379 non-null float64\n",
      "atemp         17379 non-null float64\n",
      "hum           17379 non-null float64\n",
      "windspeed     17379 non-null float64\n",
      "casual        17379 non-null int64\n",
      "registered    17379 non-null int64\n",
      "cnt           17379 non-null int64\n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
      "0            1  2011-01-01       1   0     1   0        0        6   \n",
      "1            2  2011-01-01       1   0     1   1        0        6   \n",
      "2            3  2011-01-01       1   0     1   2        0        6   \n",
      "3            4  2011-01-01       1   0     1   3        0        6   \n",
      "4            5  2011-01-01       1   0     1   4        0        6   \n",
      "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
      "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
      "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
      "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
      "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
      "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
      "\n",
      "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
      "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
      "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
      "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
      "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
      "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
      "...           ...         ...   ...     ...   ...        ...     ...   \n",
      "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
      "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
      "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
      "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
      "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
      "\n",
      "       registered  cnt  \n",
      "0              13   16  \n",
      "1              32   40  \n",
      "2              27   32  \n",
      "3              10   13  \n",
      "4               1    1  \n",
      "...           ...  ...  \n",
      "17374         108  119  \n",
      "17375          81   89  \n",
      "17376          83   90  \n",
      "17377          48   61  \n",
      "17378          37   49  \n",
      "\n",
      "[17379 rows x 17 columns]\n",
      "(17379, 16)\n",
      "(17379,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :16].values\n",
    "Y = data.iloc[:, 16].values\n",
    "\n",
    "print(data)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 ... 0.0 3 13]\n",
      " [2 0 1 ... 0.0 8 32]\n",
      " [3 0 1 ... 0.0 5 27]\n",
      " ...\n",
      " [17377 730 1 ... 0.1642 7 83]\n",
      " [17378 730 1 ... 0.1343 13 48]\n",
      " [17379 730 1 ... 0.1343 12 37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:,1] = labelencoder.fit_transform(X[:,1])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=100. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for SVR: 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 4 is smaller than n_iter=100. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for DecisionTreeRegressor: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 6 is smaller than n_iter=100. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for RandomForestRegressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for AdaBoostRegressor: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 2 is smaller than n_iter=100. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Defining kernel for GaussianProcessRegressor\n",
    "#kernel=None would take less time to train, but would give 93.7948904411872 accuracy\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "\n",
    "names = ['SVR', 'DecisionTreeRegressor', 'RandomForestRegressor', 'AdaBoostRegressor','GaussianProcessRegressor','LinearRegression','MLPRegressior']\n",
    "models = [SVR(),\n",
    "          DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          AdaBoostRegressor(),\n",
    "          GaussianProcessRegressor(kernel=kernel),\n",
    "          LinearRegression(),\n",
    "          MLPRegressor()]\n",
    "\n",
    "param_distributions = {\n",
    "    'SVR': {'C': [10,100],  'gamma': [1, 10]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [10,20,30,50]},\n",
    "    'RandomForestRegressor': {'max_depth': [20,30,50],'n_estimators': [50, 100]},\n",
    "    'AdaBoostRegressor': {'n_estimators': [50,100, 200],'learning_rate' : [0.2,0.4,1]},\n",
    "    'GaussianProcessRegressor': {},\n",
    "    'LinearRegression': {},\n",
    "    'MLPRegressior': {'hidden_layer_sizes': [(100,),(200,)],'activation':['tanh', 'relu']},\n",
    "}\n",
    "\n",
    "accuracy= np.zeros(7)\n",
    "\n",
    "for counter, model in enumerate(models):\n",
    "    np.random.seed(0);\n",
    "    randcv = RandomizedSearchCV(model, param_distributions[names[counter]], n_jobs=2, cv=3, n_iter=100)\n",
    "    randcv.fit(X_train, Y_train)\n",
    "    Y_pred  = randcv.best_estimator_.predict(X_test)\n",
    "    accuracy[counter] = round(np.sqrt(r2_score(Y_test, Y_pred)), 3)\n",
    "    print(\"R2 score for \" + names[counter] + \": \"+str(accuracy[counter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparision graph between all models\n",
    "import seaborn as sns\n",
    "y_pos = np.arange(len(names))\n",
    "heights = [accuracy[0],accuracy[1],accuracy[2],accuracy[3],accuracy[4],accuracy[5],accuracy[6]]\n",
    "\n",
    "fig, ax=plt.subplots(1,1,figsize=(12,6))\n",
    "\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=names, y=heights)\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('Bike Sharing Dataset model accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianProcessRegressor takes long time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
