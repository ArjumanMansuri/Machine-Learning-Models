{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Importing Bike Sharing Dataset\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"?\"]\n",
    "dataset = pd.read_csv('hour.csv', na_values = missing_values)\n",
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Contains Missing values                 False\n",
      "-> Total Number of Missing values:         0\n",
      "-> Number of Missing values by column\n",
      "instant       0\n",
      "dteday        0\n",
      "season        0\n",
      "yr            0\n",
      "mnth          0\n",
      "hr            0\n",
      "holiday       0\n",
      "weekday       0\n",
      "workingday    0\n",
      "weathersit    0\n",
      "temp          0\n",
      "atemp         0\n",
      "hum           0\n",
      "windspeed     0\n",
      "casual        0\n",
      "registered    0\n",
      "cnt           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has null values\n",
    "result = dataset.isna()\n",
    "print(\"-> Contains Missing values                 \",end='')\n",
    "print(result.values.any())\n",
    "print(\"-> Total Number of Missing values:         \",end='')\n",
    "print(result.sum().sum())\n",
    "print(\"-> Number of Missing values by column\")\n",
    "print(result.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      "instant       17379 non-null int64\n",
      "dteday        17379 non-null object\n",
      "season        17379 non-null int64\n",
      "yr            17379 non-null int64\n",
      "mnth          17379 non-null int64\n",
      "hr            17379 non-null int64\n",
      "holiday       17379 non-null int64\n",
      "weekday       17379 non-null int64\n",
      "workingday    17379 non-null int64\n",
      "weathersit    17379 non-null int64\n",
      "temp          17379 non-null float64\n",
      "atemp         17379 non-null float64\n",
      "hum           17379 non-null float64\n",
      "windspeed     17379 non-null float64\n",
      "casual        17379 non-null int64\n",
      "registered    17379 non-null int64\n",
      "cnt           17379 non-null int64\n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :16].values\n",
    "Y = data.iloc[:, 16].values\n",
    "\n",
    "print(data)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:,1] = labelencoder.fit_transform(X[:,1])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Defining kernel for GaussianProcessRegressor\n",
    "#kernel=None would take less time to train, but would give 93.7948904411872 accuracy\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "\n",
    "names = ['SVR', 'DecisionTreeRegressor', 'RandomForestRegressor', 'AdaBoostRegressor','GaussianProcessRegressor','LinearRegression','MLPRegressior']\n",
    "models = [SVR(),\n",
    "          DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          AdaBoostRegressor(),\n",
    "          GaussianProcessRegressor(kernel=kernel),\n",
    "          LinearRegression(),\n",
    "          MLPRegressor()]\n",
    "\n",
    "param_distributions = {\n",
    "    'SVR': {'C': [0.01, 0.1, 1, 10], 'gamma':[0.01, 0.1, 1]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [1, 10, 20, None],'min_samples_leaf': [1, 2, 4],'min_samples_split': [2, 5, 10]},\n",
    "    'RandomForestRegressor': {'max_depth': [1, 10, 20, None],'n_estimators': [16, 32, 100]},\n",
    "    'AdaBoostRegressor': {'n_estimators': [16, 32, 100],'learning_rate' : [0.2,0.4,1]},\n",
    "    'GaussianProcessRegressor': {'normalize_y': ['True','False']},\n",
    "    'LinearRegression': {},\n",
    "    'MLPRegressior': {'hidden_layer_sizes': [(100,),(200,)],'activation':['tanh', 'relu'], 'max_iter':[200,300]},\n",
    "}\n",
    "\n",
    "accuracy= np.zeros(7)\n",
    "\n",
    "for counter, model in enumerate(models):\n",
    "    gridcv = GridSearchCV(model, param_distributions[names[counter]], n_jobs=2, cv=3)\n",
    "    gridcv.fit(X_train, Y_train)\n",
    "    Y_pred  = gridcv.best_estimator_.predict(X_test)\n",
    "    accuracy[counter] = round(np.sqrt(mean_squared_error(Y_test, Y_pred)), 3)\n",
    "    print(\"RMSE for \" + names[counter] + \": \"+str(accuracy[counter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparision graph between all models\n",
    "import seaborn as sns\n",
    "y_pos = np.arange(len(names))\n",
    "heights = [accuracy[0],accuracy[1],accuracy[2],accuracy[3],accuracy[4],accuracy[5],accuracy[6]]\n",
    "\n",
    "fig, ax=plt.subplots(1,1,figsize=(12,6))\n",
    "\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=names, y=heights)\n",
    "plt.ylabel('accuracy score')\n",
    "plt.title('Bike Sharing Dataset model accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianProcessRegressor takes long time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
