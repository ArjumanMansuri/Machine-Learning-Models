{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communities and Crime Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Importing Communities and Crime Dataset\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"?\"]\n",
    "dataset = pd.read_csv('C:/Users/Manan/Desktop/Fall 2019/Machine Learning COMP6321/Project/Machine-Learning-Project/regression-models/Communities and Crime/data/communities.data', na_values = missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Contains Missing values                 True\n",
      "-> Total Number of Missing values:         39200\n",
      "-> Number of Missing values by column\n",
      "8                  0\n",
      "?               1173\n",
      "?.1             1176\n",
      "Lakewoodcity       0\n",
      "1                  0\n",
      "                ... \n",
      "0.9.1           1675\n",
      "0.5.2           1675\n",
      "0.32.2             0\n",
      "0.14.3          1675\n",
      "0.2.2              0\n",
      "Length: 128, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset has null values\n",
    "result = dataset.isna()\n",
    "print(\"-> Contains Missing values                 \",end='')\n",
    "print(result.values.any())\n",
    "print(\"-> Total Number of Missing values:         \",end='')\n",
    "print(result.sum().sum())\n",
    "print(\"-> Number of Missing values by column\")\n",
    "print(result.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing values with mean\n",
    "dataset = dataset.fillna(dataset.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Contains Missing values                 False\n",
      "-> Total Number of Missing values:         0\n",
      "-> Number of Missing values by column\n",
      "8               0\n",
      "?               0\n",
      "?.1             0\n",
      "Lakewoodcity    0\n",
      "1               0\n",
      "               ..\n",
      "0.9.1           0\n",
      "0.5.2           0\n",
      "0.32.2          0\n",
      "0.14.3          0\n",
      "0.2.2           0\n",
      "Length: 128, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(dataset)\n",
    "# Check if dataset has null values\n",
    "result = data.isna()\n",
    "print(\"-> Contains Missing values                 \",end='')\n",
    "print(result.values.any())\n",
    "print(\"-> Total Number of Missing values:         \",end='')\n",
    "print(result.sum().sum())\n",
    "print(\"-> Number of Missing values by column\")\n",
    "print(result.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8          ?           ?.1         Lakewoodcity   1  0.19  0.33  0.02  \\\n",
      "0     53  58.826829  46188.336597          Tukwilacity   1  0.00  0.16  0.12   \n",
      "1     24  58.826829  46188.336597         Aberdeentown   1  0.00  0.42  0.49   \n",
      "2     34   5.000000  81440.000000  Willingborotownship   1  0.04  0.77  1.00   \n",
      "3     42  95.000000   6096.000000    Bethlehemtownship   1  0.01  0.55  0.02   \n",
      "4      6  58.826829  46188.336597    SouthPasadenacity   1  0.02  0.28  0.06   \n",
      "...   ..        ...           ...                  ...  ..   ...   ...   ...   \n",
      "1988  12  58.826829  46188.336597    TempleTerracecity  10  0.01  0.40  0.10   \n",
      "1989   6  58.826829  46188.336597          Seasidecity  10  0.05  0.96  0.46   \n",
      "1990   9   9.000000  80070.000000        Waterburytown  10  0.16  0.37  0.25   \n",
      "1991  25  17.000000  72600.000000          Walthamcity  10  0.08  0.51  0.06   \n",
      "1992   6  58.826829  46188.336597          Ontariocity  10  0.20  0.78  0.14   \n",
      "\n",
      "       0.9  0.12  ...  0.12.2  0.26.1  0.2.1    0.06.3    0.04.2     0.9.1  \\\n",
      "0     0.74  0.45  ...    0.02    0.12   0.45  0.163428  0.076824  0.697956   \n",
      "1     0.56  0.17  ...    0.01    0.21   0.02  0.163428  0.076824  0.697956   \n",
      "2     0.08  0.12  ...    0.02    0.39   0.28  0.163428  0.076824  0.697956   \n",
      "3     0.95  0.09  ...    0.04    0.09   0.02  0.163428  0.076824  0.697956   \n",
      "4     0.54  1.00  ...    0.01    0.58   0.10  0.163428  0.076824  0.697956   \n",
      "...    ...   ...  ...     ...     ...    ...       ...       ...       ...   \n",
      "1988  0.87  0.12  ...    0.01    0.28   0.05  0.163428  0.076824  0.697956   \n",
      "1989  0.28  0.83  ...    0.02    0.37   0.20  0.163428  0.076824  0.697956   \n",
      "1990  0.69  0.04  ...    0.08    0.32   0.18  0.080000  0.060000  0.780000   \n",
      "1991  0.87  0.22  ...    0.03    0.38   0.33  0.020000  0.020000  0.790000   \n",
      "1992  0.46  0.24  ...    0.11    0.30   0.05  0.080000  0.040000  0.730000   \n",
      "\n",
      "         0.5.2  0.32.2    0.14.3  0.2.2  \n",
      "0     0.440252    0.00  0.195252   0.67  \n",
      "1     0.440252    0.00  0.195252   0.43  \n",
      "2     0.440252    0.00  0.195252   0.12  \n",
      "3     0.440252    0.00  0.195252   0.03  \n",
      "4     0.440252    0.00  0.195252   0.14  \n",
      "...        ...     ...       ...    ...  \n",
      "1988  0.440252    0.00  0.195252   0.09  \n",
      "1989  0.440252    0.00  0.195252   0.45  \n",
      "1990  0.000000    0.91  0.280000   0.23  \n",
      "1991  0.000000    0.22  0.180000   0.19  \n",
      "1992  0.500000    1.00  0.130000   0.48  \n",
      "\n",
      "[1993 rows x 128 columns]\n",
      "(1993, 127)\n",
      "(1993,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :127].values\n",
    "Y = data.iloc[:, 127].values\n",
    "\n",
    "print(data)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:,3] = labelencoder.fit_transform(X[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Manan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Defining kernel for GaussianProcessRegressor\n",
    "#kernel=None would take less time to train, but would give 93.7948904411872 accuracy\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "\n",
    "names = ['SVR', 'DecisionTreeRegressor', 'RandomForestRegressor', 'AdaBoostRegressor','GaussianProcessRegressor','LinearRegression','MLPRegressior']\n",
    "models = [SVR(),\n",
    "          DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          AdaBoostRegressor(),\n",
    "          GaussianProcessRegressor(kernel=kernel),\n",
    "          LinearRegression(),\n",
    "          MLPRegressor()]\n",
    "\n",
    "param_distributions = {\n",
    "    'SVR': {'kernel': ['linear', 'rbf','poly'],'C':[1.5, 10]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [10, 20, 90, 100, None],'min_samples_leaf': [1, 2, 4],'min_samples_split': [2, 5, 10]},\n",
    "    'RandomForestRegressor': {'max_depth': [10, 20, 90, 100, None],'n_estimators': [16, 200, 600, 800],'bootstrap': [True, False],},\n",
    "    'AdaBoostRegressor': {'n_estimators': [16, 200, 600, 800],'learning_rate' : [0.01,0.05,0.1,0.3,1],'loss' : ['linear', 'square', 'exponential']},\n",
    "    'GaussianProcessRegressor': {'normalize_y': ['True','False']},\n",
    "    'LinearRegression': {},\n",
    "    'MLPRegressior': {'hidden_layer_sizes': [(100,),(30,20)],'activation':['tanh', 'relu'],'learning_rate' : [0.01,0.05,0.1,0.3,1],'max_iter': [100,200]},\n",
    "}\n",
    "\n",
    "accuracy= np.zeros(7)\n",
    "\n",
    "for counter, model in enumerate(models):\n",
    "    gridcv = GridSearchCV(estimator = model, param_grid = param_distributions[names[counter]], verbose=1,cv=3)\n",
    "    gridcv.fit(X_train, Y_train)\n",
    "    grid_accuracy_test = gridcv.best_estimator_.score(X_test, Y_test)\n",
    "#     grid_accuracy_test  = sklearn.metrics.accuracy_score(Y_test,  gridcv.best_estimator_.predict(X_test))\n",
    "    accuracy[counter] = grid_accuracy_test*100\n",
    "    print(\"Accuracy for \" + names[counter] + \":\",accuracy[counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparision graph between all models\n",
    "import seaborn as sns\n",
    "y_pos = np.arange(len(names))\n",
    "heights = [accuracy[0],accuracy[1],accuracy[2],accuracy[3],accuracy[4],accuracy[5],accuracy[6]]\n",
    "\n",
    "fig, ax=plt.subplots(1,1,figsize=(12,6))\n",
    "\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=names, y=heights)\n",
    "plt.ylabel('accuracy score')\n",
    "plt.title('Communities and Crime Dataset model accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
