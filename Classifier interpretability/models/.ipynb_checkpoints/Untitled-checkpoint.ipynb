{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def get_data_labels(dict_):\n",
    "    dict_decoded_ = {}\n",
    "    for key,value in dict_.items():\n",
    "            if(isinstance(key,bytes)):\n",
    "                key_new = key.decode('ascii')\n",
    "            if(isinstance(value,bytes)):\n",
    "                value = value.decode('ascii')\n",
    "            dict_decoded_[key_new] = value\n",
    "    return dict_decoded_['data'],dict_decoded_['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset files\n",
    "path = 'cifar-10-python/cifar-10-batches-py/'\n",
    "files = os.listdir(path)\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "for name in files:\n",
    "    if 'data_batch' in name:\n",
    "        dict_ = unpickle(path+name)  # unpickling the data_batch file\n",
    "        X_temp,y_temp = get_data_labels(dict_)  # getting data and labels from unpickled data\n",
    "        X_train.append(X_temp)\n",
    "        y_train.append(y_temp)\n",
    "X_train = np.asarray(X_train).astype(np.uint8).reshape(50000,3072)\n",
    "y_train = np.asarray(y_train).astype(np.int32)\n",
    "X_train = X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "dict_ = unpickle(path+'test_batch')  # unpickling the test_batch file\n",
    "X_test,y_test = get_data_labels(dict_)  # getting data and labels from unpickled data\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.uint8)\n",
    "y_test = np.asarray(y_test).astype(np.int32)\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = torch.tensor(scaler.transform(X_train))\n",
    "X_test = torch.tensor(scaler.transform(X_test))\n",
    "\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([50000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# reshaping tensors for CNN\n",
    "X_train = X_train.reshape(50000,3,32,32)\n",
    "X_test = X_test.reshape(-1,3,32,32)\n",
    "print(X_train.shape)\n",
    "y_train = y_train.reshape(50000)\n",
    "print(y_train.shape)\n",
    "y_test = y_test.reshape(-1)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the model\n",
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "num_filters = 5\n",
    "filter_size_1 = 4\n",
    "filter_size_2 = 6\n",
    "pool_size = 2\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=3,\n",
    "                    out_channels=num_filters,\n",
    "                    kernel_size=filter_size_1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(in_channels=num_filters,\n",
    "                    out_channels=filter_size_2,\n",
    "                    kernel_size=filter_size_2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(filter_size_2 * 12**2, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epoch = 13\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0060,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 final minibatch had loss 1.6065\n",
      "Epoch 2 final minibatch had loss 1.5060\n",
      "Epoch 3 final minibatch had loss 1.4220\n",
      "Epoch 4 final minibatch had loss 1.3652\n",
      "Epoch 5 final minibatch had loss 1.3126\n",
      "Epoch 6 final minibatch had loss 1.2573\n",
      "Epoch 7 final minibatch had loss 1.1978\n",
      "Epoch 8 final minibatch had loss 1.1647\n",
      "Epoch 9 final minibatch had loss 1.1392\n",
      "Epoch 10 final minibatch had loss 1.1192\n",
      "Epoch 11 final minibatch had loss 1.0889\n",
      "Epoch 12 final minibatch had loss 1.0945\n",
      "Epoch 13 final minibatch had loss 1.0880\n"
     ]
    }
   ],
   "source": [
    "# loss would be 1.0937 in the last epoch\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    for i in range(0, len(X_train), batch_size):        \n",
    "        X = X_train[i:i+batch_size]\n",
    "        y = y_train[i:i+batch_size]\n",
    "\n",
    "        y_pred = model(X.float())\n",
    "        l = loss(y_pred, y.long())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch %d final minibatch had loss %.4f\" % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.60452\n"
     ]
    }
   ],
   "source": [
    "# calculate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_train.float())\n",
    "    \n",
    "softmax = torch.exp(y_pred).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "y_pred = np.argmax(prob, axis=1)\n",
    "\n",
    "# accuracy on training set\n",
    "print('Training accuracy is '+str(accuracy_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy is 0.56\n"
     ]
    }
   ],
   "source": [
    "# calculate test accuracy\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test.float())\n",
    "    \n",
    "softmax = torch.exp(y_test_pred).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "y_test_pred = np.argmax(prob, axis=1)\n",
    "\n",
    "# accuracy on training set\n",
    "print('Testing accuracy is '+str(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "param_distribution = {'criterion':['gini','entropy'], 'max_depth': range(1,10,2)}\n",
    "\n",
    "gridcv = GridSearchCV(model, param_distribution, verbose=1, n_jobs=4, cv=3)\n",
    "gridcv.fit(X_train, Y_train)\n",
    "grid_accuracy_test  = sklearn.metrics.accuracy_score(Y_test,  gridcv.best_estimator_.predict(X_test))\n",
    "accuracy[counter] = grid_accuracy_test*100\n",
    "print(\"Accuracy for \" + names[counter] + \":\",accuracy[counter])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
